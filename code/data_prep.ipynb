{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe154893-1072-498a-9cf7-3366c34edf00",
   "metadata": {},
   "source": [
    "# It runs now!!\n",
    "## Fixed issues:\n",
    "- Queen \n",
    "- ix\n",
    "- file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212138a6-c717-4c9d-b516-1a896d956d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysal\n",
      "  Downloading pysal-23.1-py3-none-any.whl (17 kB)\n",
      "Collecting momepy>=0.5.4\n",
      "  Downloading momepy-0.6.0-py3-none-any.whl (275 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting splot>=1.1.5.post1\n",
      "  Downloading splot-1.1.5.post1-py3-none-any.whl (39 kB)\n",
      "Collecting mgwr>=2.1.2\n",
      "  Downloading mgwr-2.1.2.tar.gz (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting inequality>=1.0.0\n",
      "  Downloading inequality-1.0.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting esda>=2.4.1\n",
      "  Downloading esda-2.4.3.tar.gz (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spglm>=1.0.8\n",
      "  Downloading spglm-1.0.8.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting libpysal>=4.7.0\n",
      "  Downloading libpysal-4.7.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting segregation>=2.3.1\n",
      "  Downloading segregation-2.4.2-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spreg>=1.3.0\n",
      "  Downloading spreg-1.3.2-py3-none-any.whl (220 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.2/220.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spint>=1.0.7\n",
      "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pointpats>=2.2.0\n",
      "  Downloading pointpats-2.3.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spvcm>=0.3.0\n",
      "  Downloading spvcm-0.3.0.tar.gz (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tobler>=0.8.2\n",
      "  Downloading tobler-0.10-py3-none-any.whl (30 kB)\n",
      "Collecting mapclassify>=2.5.0\n",
      "  Downloading mapclassify-2.5.0-py3-none-any.whl (39 kB)\n",
      "Collecting giddy>=2.3.3\n",
      "  Downloading giddy-2.3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting access>=1.1.8\n",
      "  Downloading access-1.1.9-py3-none-any.whl (21 kB)\n",
      "Collecting spopt>=0.5.0\n",
      "  Downloading spopt-0.5.0-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spaghetti>=1.7.2\n",
      "  Downloading spaghetti-1.7.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting geopandas\n",
      "  Downloading geopandas-0.13.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from access>=1.1.8->pysal) (2.28.1)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from access>=1.1.8->pysal) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.3 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from access>=1.1.8->pysal) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.11 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from esda>=2.4.1->pysal) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from esda>=2.4.1->pysal) (1.0.2)\n",
      "Collecting quantecon>=0.4.7\n",
      "  Downloading quantecon-0.7.1-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.8/214.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from libpysal>=4.7.0->pysal) (21.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from libpysal>=4.7.0->pysal) (4.11.1)\n",
      "Requirement already satisfied: jinja2 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from libpysal>=4.7.0->pysal) (2.11.3)\n",
      "Requirement already satisfied: platformdirs in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from libpysal>=4.7.0->pysal) (2.5.2)\n",
      "Requirement already satisfied: networkx in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from mapclassify>=2.5.0->pysal) (2.8.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from momepy>=0.5.4->pysal) (4.64.1)\n",
      "Collecting shapely>=2\n",
      "  Downloading shapely-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from pointpats>=2.2.0->pysal) (3.5.2)\n",
      "Collecting pyproj>=3\n",
      "  Downloading pyproj-3.6.0-cp39-cp39-macosx_10_9_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from segregation>=2.3.1->pysal) (0.55.1)\n",
      "Requirement already satisfied: joblib in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from segregation>=2.3.1->pysal) (1.1.0)\n",
      "Requirement already satisfied: seaborn in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from segregation>=2.3.1->pysal) (0.11.2)\n",
      "Collecting deprecation\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: rtree in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from spaghetti>=1.7.2->pysal) (0.9.7)\n",
      "Collecting pulp\n",
      "  Downloading PuLP-2.7.0-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from tobler>=0.8.2->pysal) (0.13.2)\n",
      "Collecting rasterstats\n",
      "  Downloading rasterstats-0.19.0-py3-none-any.whl (16 kB)\n",
      "Collecting rasterio\n",
      "  Downloading rasterio-1.3.7-cp39-cp39-macosx_10_15_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fiona>=1.8.19\n",
      "  Downloading Fiona-1.9.4.post1-cp39-cp39-macosx_10_15_x86_64.whl (18.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->access>=1.1.8->pysal) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->access>=1.1.8->pysal) (2022.1)\n",
      "Requirement already satisfied: certifi in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from pyproj>=3->segregation>=2.3.1->pysal) (2022.9.24)\n",
      "Requirement already satisfied: sympy in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from quantecon>=0.4.7->giddy>=2.3.3->pysal) (1.10.1)\n",
      "Requirement already satisfied: setuptools in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from numba->segregation>=2.3.1->pysal) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from numba->segregation>=2.3.1->pysal) (0.38.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from requests>=2->access>=1.1.8->pysal) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from requests>=2->access>=1.1.8->pysal) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from requests>=2->access>=1.1.8->pysal) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->esda>=2.4.1->pysal) (2.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->libpysal>=4.7.0->pysal) (2.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from jinja2->libpysal>=4.7.0->pysal) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->pointpats>=2.2.0->pysal) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->pointpats>=2.2.0->pysal) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->pointpats>=2.2.0->pysal) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->pointpats>=2.2.0->pysal) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->pointpats>=2.2.0->pysal) (0.11.0)\n",
      "Collecting click-plugins\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Collecting affine\n",
      "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click>=4.0 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from rasterio->tobler>=0.8.2->pysal) (8.0.4)\n",
      "Requirement already satisfied: attrs in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from rasterio->tobler>=0.8.2->pysal) (21.4.0)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.19.1-cp39-cp39-macosx_10_9_x86_64.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.5.2 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from statsmodels->tobler>=0.8.2->pysal) (0.5.2)\n",
      "Requirement already satisfied: six in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from fiona>=1.8.19->geopandas->access>=1.1.8->pysal) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from fiona>=1.8.19->geopandas->access>=1.1.8->pysal) (4.11.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from sympy->quantecon>=0.4.7->giddy>=2.3.3->pysal) (1.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata->fiona>=1.8.19->geopandas->access>=1.1.8->pysal) (3.8.0)\n",
      "Building wheels for collected packages: esda, inequality, mgwr, spglm, spint, spvcm\n",
      "  Building wheel for esda (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for esda: filename=esda-2.4.3-py3-none-any.whl size=122765 sha256=382853cbeaba6d8c2dd44dcbf849a87cdde7d218ff470de914fbf161ef48da49\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/92/4b/14/df69615cd54ad1ce64b70d141dee8b269ebc7ace679cef9f3f\n",
      "  Building wheel for inequality (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for inequality: filename=inequality-1.0.0-py3-none-any.whl size=11782 sha256=c4abdf62d49a6e4e4b3969e4a5594f0200136fc126b3ef69bb5aa0704b0f42a9\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/80/71/07/4d4c8ecaba710bd79e91014602e70fc4d008328c99d524db40\n",
      "  Building wheel for mgwr (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mgwr: filename=mgwr-2.1.2-py3-none-any.whl size=46366 sha256=5e131cde9fe9f7ab01263dcc2187b1aec6c18c30b4702c48b7621fc58ec2fadd\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/7f/03/f3/6d95ff5d1911ba9e13f98d96dab2afb10969270ee75ab82bc8\n",
      "  Building wheel for spglm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spglm: filename=spglm-1.0.8-py3-none-any.whl size=38786 sha256=b41916179c0ec001018d713a4544cf22d4bd953ec86bffb46f75596dc4956728\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/c2/b8/7e/709d2af4286d94d611711d81727d40149e7467ca9a43c5e30c\n",
      "  Building wheel for spint (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31364 sha256=4489e097f585577c73ad6a4af9e18474d827b72fd6e7fce057a7e1f6fcb989b2\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/93/a7/ea/0e65be5d06cd2860a4c2ea99656ead582f96aa3954652b6ad7\n",
      "  Building wheel for spvcm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spvcm: filename=spvcm-0.3.0-py3-none-any.whl size=5777185 sha256=a66b4440d2b111debce160695d01a41437e70e6a737602fe37ffc0b1e55dda4e\n",
      "  Stored in directory: /Users/liamsmith/Library/Caches/pip/wheels/73/d0/2c/ef650f39e25225566643b2839ebfe7a2d4adc5d777dc8d7d73\n",
      "Successfully built esda inequality mgwr spglm spint spvcm\n",
      "Installing collected packages: pulp, snuggs, simplejson, shapely, pyproj, cligj, click-plugins, affine, rasterio, quantecon, inequality, fiona, deprecation, rasterstats, mapclassify, libpysal, geopandas, tobler, spreg, segregation, pointpats, momepy, esda, access, spvcm, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal\n",
      "Successfully installed access-1.1.9 affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 deprecation-2.1.0 esda-2.4.3 fiona-1.9.4.post1 geopandas-0.13.2 giddy-2.3.4 inequality-1.0.0 libpysal-4.7.0 mapclassify-2.5.0 mgwr-2.1.2 momepy-0.6.0 pointpats-2.3.0 pulp-2.7.0 pyproj-3.6.0 pysal-23.1 quantecon-0.7.1 rasterio-1.3.7 rasterstats-0.19.0 segregation-2.4.2 shapely-2.0.1 simplejson-3.19.1 snuggs-1.4.7 spaghetti-1.7.3 spglm-1.0.8 spint-1.0.7 splot-1.1.5.post1 spopt-0.5.0 spreg-1.3.2 spvcm-0.3.0 tobler-0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pysal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "86662a3f-25f0-4e5d-9cfc-aef2699c168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not pull supplementary ACS data - A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n",
      "  warnings.warn(dep_msg, FutureWarning)\n",
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n",
      "  warnings.warn(dep_msg, FutureWarning)\n",
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 10 disconnected components.\n",
      " There are 7 islands with ids: 68, 546, 547, 549, 1226, 1876, 2976.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 68, ' is an island (no neighbors)')\n",
      "('WARNING: ', 546, ' is an island (no neighbors)')\n",
      "('WARNING: ', 547, ' is an island (no neighbors)')\n",
      "('WARNING: ', 549, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1226, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1876, ' is an island (no neighbors)')\n",
      "('WARNING: ', 2976, ' is an island (no neighbors)')\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env\n",
    "\n",
    "# This script loads and prepares Census and ACS data.\n",
    "# Outputs a CSV file that can be used for the construction of SoVI\n",
    "# Interpolates missing values using nearby values\n",
    "# Calculates SE for compositve variables\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pysal as ps\n",
    "import numpy as np\n",
    "import libpysal as lps\n",
    "# @TODO: Finish Doc strings\n",
    "# @TODO: Cleanup file\n",
    "\n",
    "\n",
    "pd.set_option(\"chained_assignment\", None)\n",
    "\n",
    "# path = os.getcwd()\n",
    "path = os.path.dirname(os.getcwd()) # if running from the 'code' directory\n",
    "outPath=os.path.join(path,'data')\n",
    "ipath = os.path.join(path,'data','input')\n",
    "spath = os.path.join(path,'data','spatial')\n",
    "#\n",
    "# functions fot the calculation of SE\n",
    "\n",
    "\n",
    "def se_sum(*ses):\n",
    "    \"\"\"\n",
    "    compute the standard errors for a composite (sum) variable)\n",
    "\n",
    "    :param ses: an arbitrary number of standard errors for variables participating in a sum (composite variable)\n",
    "    :return: Data frame containing standard errors for the composite variable\n",
    "    \"\"\"\n",
    "\n",
    "    df_temp = pd.DataFrame(list(ses))\n",
    "    df_temp = df_temp.T\n",
    "    df_temp = np.square(df_temp)\n",
    "    df_temp = df_temp.sum(1)\n",
    "    return np.sqrt(df_temp)\n",
    "\n",
    "\n",
    "# SE of a ratio\n",
    "def se_ratio(est, estd, sen, sed):\n",
    "    \"\"\"\n",
    "\n",
    "    :param est:\n",
    "    :param estd:\n",
    "    :param sen:\n",
    "    :param sed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    sen2 = np.square(sen)\n",
    "    sed2 = np.square(sed)\n",
    "    est2 = np.square(est)\n",
    "    num = np.sqrt(sen2 + (est2 * sed2))\n",
    "    return num / estd\n",
    "\n",
    "\n",
    "# SE of a proprotion\n",
    "def se_prop(est, estd, sen, sed):\n",
    "    sen2 = np.square(sen)\n",
    "    sed2 = np.square(sed)\n",
    "    est2 = np.square(est)\n",
    "    num = sen2 - (est2 * sed2)\n",
    "    num_alt = sen2 + (est2 * sed2)\n",
    "    problems = num <= 0\n",
    "    num[problems] = num_alt[problems]\n",
    "    num = np.sqrt(num)\n",
    "    return num / estd\n",
    "\n",
    "\n",
    "# unit test for equivalency between original and constructed variables\n",
    "def equal_test(orig, alt):\n",
    "    if np.equal(orig, alt).sum() != db.shape[0]:\n",
    "        if (db.shape[0] - np.equal(orig, alt).sum()) \\\n",
    "                == np.isnan(orig).sum() == np.isnan(alt).sum():\n",
    "            pass\n",
    "        else:\n",
    "            print(\"problem in equal test\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# define data types\n",
    "make_strings = {'Geo_FIPS': object, 'Geo_STATE': object, 'Geo_COUNTY': object,\n",
    "                'Geo_TRACT': object, 'Geo_CBSA': object, 'Geo_CSA': object}\n",
    "\n",
    "# load data\n",
    "# JOE: I had to change the encoding to latin-1 to avoid hitting a UTF-8 error\n",
    "acs = pd.read_csv(os.path.join(ipath, 'sovi_acs.csv'),\n",
    "                  dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "census = pd.read_csv(os.path.join(ipath, 'sovi_decennial.csv'),\n",
    "                     dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "acs_samp = pd.read_csv(os.path.join(ipath, 'sovi_acs_sampSize.csv'),\n",
    "                       dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "\n",
    "# format FIPS\n",
    "acs.index = 'g' + acs.Geo_FIPS\n",
    "census.index = 'g' + census.Geo_FIPS\n",
    "acs_samp.index = 'g' + acs_samp.Geo_FIPS\n",
    "\n",
    "# merge files\n",
    "db = census\n",
    "db = db.join(acs, rsuffix='_acs')\n",
    "db = db.join(acs_samp, rsuffix='_acsSamp')\n",
    "\n",
    "# if available add supplmentary data\n",
    "try:\n",
    "    census_sup1 = pd.read_csv(os.path.join(ipath, 'sovi_decennial_sup1.csv'),\n",
    "        dtype=make_strings,skiprows=1,encoding='latin-1')\n",
    "    census_sup1.index = 'g' + census_sup1.Geo_FIPS\n",
    "    db = db.join(census_sup1, rsuffix='_decSup1')\n",
    "except:\n",
    "    print(\"no supplementary decennial data\")\n",
    "try:\n",
    "    acs_sup1 = pd.read_csv(os.path.join(spath, 'sovi_acs_sup1.csv'),\n",
    "        dtype=make_strings,skiprows=1,encoding='latin-1')\n",
    "    acs_sup1.index = 'g' + acs_sup1.Geo_FIPS\n",
    "    db = db.join(acs_sup1, rsuffix='_acsSup1')\n",
    "except:\n",
    "    print(\"did not pull supplementary ACS data - A\")\n",
    "try:\n",
    "    acs_sup2 = pd.read_csv(os.path.join(ipath, 'sovi_acs_kids.csv'),\n",
    "                           dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "    acs_sup2.index = 'g' + acs_sup2.Geo_FIPS\n",
    "    db = db.join(acs_sup2, rsuffix='_acsSup2')\n",
    "except:\n",
    "    print(\"did not pull supplementary ACS data - B\")\n",
    "\n",
    "# drop Puerto Rico (sorry PR!)\n",
    "db = db[db.Geo_STATE != '72']\n",
    "\n",
    "# define SE columns\n",
    "se_cols = [i for i in db.columns if i[-1] == 's' and i[0] == 'A']\n",
    "db[se_cols] *= (1.65 / 1.645)\n",
    "\n",
    "# calculate weights matrix\n",
    "# w = ps.queen_from_shapefile(os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "#                             idVariable='geoFIPS')\n",
    "# queen_from_shapefile is OUTDATED. New version below?\n",
    "# w = libpysal.weights.Queen.from_dataframe(os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "                            # idVariable='geoFIPS')\n",
    "# w = ps.lib.io.weights.Queen.from_dataframe(polygons = os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "                            # ids = 'geoFIPS')\n",
    "gdf = gpd.read_file(os.path.join(spath, 'USA_Counties_500k.shp'))\n",
    "\n",
    "w = lps.weights.Queen.from_shapefile(os.path.join(spath, 'USA_Counties_500k.shp'))\n",
    "    #os.path.join(spath, 'USA_Counties_500k.shp')) \n",
    "#                            ids = 'geoFIPS')\n",
    "\n",
    "w.transform = 'R'\n",
    "\n",
    "# output dataframe\n",
    "db1 = pd.DataFrame(index=db.index)\n",
    "\n",
    "# Decennial variables (original)\n",
    "db1['MEDAGE'] = db.SF1_P0130001\n",
    "db1['BLACK'] = (db.SF1_P0030003 * 1.) / db.SF1_P0010001\n",
    "db1['QNATAM'] = (db.SF1_P0030004 * 1.) / db.SF1_P0010001\n",
    "db1['QASIAN'] = (db.SF1_P0030005 * 1.) / db.SF1_P0010001\n",
    "db1['QHISP'] = (db.SF1_P0040003 * 1.) / db.SF1_P0010001\n",
    "db1['QAGEDEP'] = ((db.SF1_P0120003 + db.SF1_P0120027 + db.SF1_P0120020 +\n",
    "                   db.SF1_P0120021 + db.SF1_P0120022 + db.SF1_P0120023 +\n",
    "                   db.SF1_P0120024 + db.SF1_P0120025 + db.SF1_P0120044 +\n",
    "                   db.SF1_P0120045 + db.SF1_P0120046 + db.SF1_P0120047 +\n",
    "                   db.SF1_P0120048 + db.SF1_P0120049) * 1.) / db.SF1_P0010001\n",
    "db1['PPUNIT'] = db.SF1_H0100001 / (db.SF1_H0030002 * 1.)\n",
    "db1['PRENTER'] = (db.SF1_H0040004 * 1.) / db.SF1_H0010001\n",
    "db1['QNRRES'] = (db.SF1_P0420005 * 1.) / db.SF1_P0010001\n",
    "db1['QFEMALE'] = (db.SF1_P0120026 * 1.) / db.SF1_P0010001\n",
    "db1['QFHH'] = (db.SF1_P0190014 * 1.) / db.SF1_P0180001\n",
    "db1['QUNOCCHU'] = ((db.SF1_H0010001 - db.SF1_H0030002) * 1.) / db.SF1_H0010001\n",
    "\n",
    "# Decennial variables (alternatives)\n",
    "db1['BLACK_ALT'] = (db.SF1_P0050004 * 1.) / db.SF1_P0010001  # exclude hispanic\n",
    "db1['QNATAM_ALT'] = (db.SF1_P0050005 * 1.) / \\\n",
    "                    db.SF1_P0010001  # exclude hispanic\n",
    "db1['QASIAN_ALT'] = (db.SF1_P0050006 * 1.) / \\\n",
    "                    db.SF1_P0010001  # exclude hispanic\n",
    "db1['QNRRES_ALT'] = (db.SF1_P0430023 + db.SF1_P0430054 * 1.) / \\\n",
    "                    db.SF1_P0010001  # 65 and over living in group quarters\n",
    "# same value, simplified computation\n",
    "db1['QUNOCCHU_ALT'] = (db.SF1_H0030003 * 1.) / db.SF1_H0030001\n",
    "\n",
    "# Decennial variables (using ACS data and alternative formulations)\n",
    "db1['MEDAGE_ACS'] = db.ACS12_5yr_B01002001\n",
    "db1['BLACK_ACS'] = db.ACS12_5yr_B03002004 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QNATAM_ACS'] = db.ACS12_5yr_B03002005 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QASIAN_ACS'] = db.ACS12_5yr_B03002006 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QHISP_ACS'] = db.ACS12_5yr_B03002012 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QAGEDEP_ACS'] = (db.ACS12_5yr_B06001002 + db.ACS12_5yr_B09020001) / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QPUNIT_ACS'] = db.ACS12_5yr_B25008001 / (db.ACS12_5yr_B25002002 * 1.)\n",
    "db1['PRENTER_ACS'] = db.ACS12_5yr_B25003003 / (db.ACS12_5yr_B25002001 * 1.)\n",
    "db1['QNRRES_ACS'] = db.ACS12_5yr_B09020021 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QFEMALE_ACS'] = db.ACS12_5yr_B01001026 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QFHH_ACS'] = db.ACS12_5yr_B11001006 / (db.ACS12_5yr_B11001001 * 1.)\n",
    "db1['QUNOCCHU_ACS'] = db.ACS12_5yr_B25002003 / (db.ACS12_5yr_B25002001 * 1.)\n",
    "\n",
    "# ACS variables (original)\n",
    "db1['PERCAP'] = db.ACS12_5yr_B19025001 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QESL'] = ((db.ACS12_5yr_B16004029 + db.ACS12_5yr_B16004030 +\n",
    "                db.ACS12_5yr_B16004034 + db.ACS12_5yr_B16004035 +\n",
    "                db.ACS12_5yr_B16004039 + db.ACS12_5yr_B16004040 +\n",
    "                db.ACS12_5yr_B16004044 + db.ACS12_5yr_B16004045 +\n",
    "                db.ACS12_5yr_B16004051 + db.ACS12_5yr_B16004052 +\n",
    "                db.ACS12_5yr_B16004056 + db.ACS12_5yr_B16004057 +\n",
    "                db.ACS12_5yr_B16004061 + db.ACS12_5yr_B16004062 +\n",
    "                db.ACS12_5yr_B16004066 + db.ACS12_5yr_B16004067) * 1.) / \\\n",
    "              ((db.ACS12_5yr_B16004024 + db.ACS12_5yr_B16004046) - (db.ACS12_5yr_B16004025 + db.ACS12_5yr_B16004047))\n",
    "db1.QESL = db1.QESL.replace([np.inf, -np.inf, np.nan], 0)\n",
    "db1.QESL = db1.QESL.replace([np.inf, -np.inf], 0)\n",
    "db1['QCVLUN'] = ((db.ACS12_5yr_B23022025 + db.ACS12_5yr_B23022049) * 1.) / \\\n",
    "                db.ACS12_5yr_B23022001\n",
    "db1['QPOVTY'] = (db.ACS12_5yr_B17021002 * 1.) / db.ACS12_5yr_B17021001\n",
    "db1['QMOHO'] = (db.ACS12_5yr_B25024010 * 1.) / db.ACS12_5yr_B25024001\n",
    "db1['QED12LES'] = ((db.ACS12_5yr_B15002003 + db.ACS12_5yr_B15002004 +\n",
    "                    db.ACS12_5yr_B15002005 + db.ACS12_5yr_B15002006 +\n",
    "                    db.ACS12_5yr_B15002007 + db.ACS12_5yr_B15002008 +\n",
    "                    db.ACS12_5yr_B15002009 + db.ACS12_5yr_B15002010 +\n",
    "                    db.ACS12_5yr_B15002020 + db.ACS12_5yr_B15002021 +\n",
    "                    db.ACS12_5yr_B15002022 + db.ACS12_5yr_B15002023 +\n",
    "                    db.ACS12_5yr_B15002024 + db.ACS12_5yr_B15002025 +\n",
    "                    db.ACS12_5yr_B15002026 + db.ACS12_5yr_B15002027) * 1.) / \\\n",
    "                  db.ACS12_5yr_B15002001\n",
    "db1['QFEMLBR'] = (db.ACS12_5yr_C24010038 * 1.) / db.ACS12_5yr_C24010001\n",
    "db1['QEXTRCT'] = ((db.ACS12_5yr_C24030003 + db.ACS12_5yr_C24030030) * 1.) / \\\n",
    "                 db.ACS12_5yr_C24030001\n",
    "db1['QSERV'] = ((db.ACS12_5yr_C24010019 + db.ACS12_5yr_C24010055) * 1.) / \\\n",
    "               db.ACS12_5yr_C24010001\n",
    "db1['QSSBEN'] = (db.ACS12_5yr_B19055002 * 1.) / db.ACS12_5yr_B19055001\n",
    "db1['QNOAUTO'] = ((db.ACS12_5yr_B25044003 + db.ACS12_5yr_B25044010) * 1.) / \\\n",
    "                 db.ACS12_5yr_B25044001\n",
    "db1['QFAM'] = (db.ACS12_5yr_B09002002 * 1.) / db.ACS12_5yr_B09002001\n",
    "db1.QFAM = db1.QFAM.replace([np.inf, -np.inf, np.nan], 0)\n",
    "db1['QRICH200K'] = (db.ACS12_5yr_B19001017 * 1.) / db.ACS12_5yr_B11001001\n",
    "\n",
    "# ACS variables (alternatives)\n",
    "# HH income divided by persons in HHs\n",
    "db1['PERCAP_ALT'] = db.ACS12_5yr_B19025001 / (db.ACS12_5yr_B25008001 * 1.)\n",
    "\n",
    "# 5 and older who don't speak English very well\n",
    "db1['QESL_ALT'] = ((db.ACS12_5yr_B06007005 + db.ACS12_5yr_B06007008) * 1.) / \\\n",
    "                  db.ACS12_5yr_B06007001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QED12LES_ALT'] = (db.ACS12_5yr_B16010002 * 1.) / db.ACS12_5yr_B16010001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QEXTRCT_ALT'] = (db.ACS12_5yr_C24050002 * 1.) / db.ACS12_5yr_C24050001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QSERV_ALT'] = (db.ACS12_5yr_C24050029 * 1.) / db.ACS12_5yr_C24050001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QNOAUTO_ALT'] = (db.ACS12_5yr_B08201002 * 1.) / db.ACS12_5yr_B08201001\n",
    "\n",
    "# the original computed the median by hand so is not included\n",
    "db1['MDGRENT_ALT'] = db.ACS12_5yr_B25064001\n",
    "\n",
    "# the original computed the median by hand so is not included\n",
    "db1['MHSEVAL_ALT'] = db.ACS12_5yr_B25077001\n",
    "\n",
    "# I didn't understand QURBRURX\n",
    "db1['POPDENS'] = db.ACS12_5yr_B01003001 / (db.SE_T02A_002 * 1.)\n",
    "\n",
    "# if no home value, assign the spatial lag of the estimate and SE\n",
    "# NOTE: when they do this, they appear to be doing some extra work... the goal is to replace missing home values with\n",
    "# their spatial lag. But after calculating spatial lag, they replace missing spatial lags with the home value in that county,\n",
    "# which is circular. Also we probably don't need to calculate spatial lag on the whole dataset -- why not do it for just the \n",
    "# observations that we are missing data for?\n",
    "homeval = db1['MHSEVAL_ALT'].copy()\n",
    "homeval_se = db.ACS12_5yr_B25077001s.copy()\n",
    "dbf = lps.io.open(os.path.join(spath, 'USA_Counties_500k.dbf'))\n",
    "\n",
    "# Rename dbf GEOIDs to match homeval\n",
    "geoid = dbf.by_col('geoFIPS')\n",
    "\n",
    "shp_fips = pd.DataFrame(dbf.by_col('geoFIPS'), index=geoid)\n",
    "shp_fips = shp_fips.join(homeval)\n",
    "shp_fips = shp_fips.join(homeval_se)\n",
    "shp_fips['MHSEVAL_ALT_LAG'] = lps.weights.lag_spatial(w, shp_fips.MHSEVAL_ALT)\n",
    "shp_fips['MHSEVAL_ALT_LAG_SE'] = lps.weights.lag_spatial(w, shp_fips.ACS12_5yr_B25077001s)\n",
    "\n",
    "mh = shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG == 0].MHSEVAL_ALT.tolist()\n",
    "\n",
    "# Reassign values to MHSEVAL_ALT_LAG\n",
    "shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG == 0, 'MHSEVAL_ALT_LAG'] = mh\n",
    "\n",
    "# Reassign missing standard error values\n",
    "mhs = shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG_SE == 0].ACS12_5yr_B25077001s.tolist()\n",
    "shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG_SE == 0, 'MHSEVAL_ALT_LAG_SE'] = mhs\n",
    "\n",
    "# Get rid of nan values - reassign MHSEVAL_ALT(_SE)\n",
    "shp_fips.MHSEVAL_ALT_LAG[np.isnan(shp_fips.MHSEVAL_ALT_LAG)] = \\\n",
    "    shp_fips.MHSEVAL_ALT[np.isnan(shp_fips.MHSEVAL_ALT_LAG)]  # replace NA with lag\n",
    "shp_fips.MHSEVAL_ALT_LAG_SE[np.isnan(shp_fips.MHSEVAL_ALT_LAG_SE)] = \\\n",
    "    shp_fips.ACS12_5yr_B25077001s[np.isnan(shp_fips.MHSEVAL_ALT_LAG_SE)]  # replace NA with lag\n",
    "\n",
    "db1['MHSEVAL_ALT_LAG'] = shp_fips['MHSEVAL_ALT_LAG']\n",
    "db1['MHSEVAL_ALT_LAG_SE'] = shp_fips['MHSEVAL_ALT_LAG_SE']\n",
    "db1.MHSEVAL_ALT[np.isnan(db1.MHSEVAL_ALT)] = db1.MHSEVAL_ALT_LAG[np.isnan(db1.MHSEVAL_ALT)]\n",
    "# note: the lagged SE is pushed to the final column in the SE section below\n",
    "\n",
    "#############################\n",
    "\n",
    "# Decennial standard errors (using ACS data and alternative formulations)\n",
    "db1['MEDAGE_ACS_SE'] = db.ACS12_5yr_B01002001s\n",
    "\n",
    "db1['BLACK_ACS_SE'] = se_prop(db1.BLACK_ACS, db.ACS12_5yr_B03002001,\n",
    "                              db.ACS12_5yr_B03002004s, db.ACS12_5yr_B03002001s)\n",
    "db1['QNATAM_ACS_SE'] = se_prop(db1.QNATAM_ACS, db.ACS12_5yr_B03002001,\n",
    "                               db.ACS12_5yr_B03002005s, db.ACS12_5yr_B03002001s)\n",
    "db1['QASIAN_ACS_SE'] = se_prop(db1.QASIAN_ACS, db.ACS12_5yr_B03002001,\n",
    "                               db.ACS12_5yr_B03002006s, db.ACS12_5yr_B03002001s)\n",
    "db1['QHISP_ACS_SE'] = se_prop(db1.QHISP_ACS, db.ACS12_5yr_B03002001,\n",
    "                              db.ACS12_5yr_B03002012s, db.ACS12_5yr_B03002001s)\n",
    "\n",
    "QAGEDEP_ACS_sen = se_sum(db.ACS12_5yr_B06001002s, db.ACS12_5yr_B09020001s)\n",
    "db1['QAGEDEP_ACS_SE'] = se_prop(db1.QAGEDEP_ACS, db.ACS12_5yr_B01003001,\n",
    "                                QAGEDEP_ACS_sen, db.ACS12_5yr_B01003001s)\n",
    "\n",
    "db1['QPUNIT_ACS_SE'] = se_ratio(db1.QPUNIT_ACS, db.ACS12_5yr_B25002002,\n",
    "                                db.ACS12_5yr_B25008001s, db.ACS12_5yr_B25002002s)\n",
    "db1['PRENTER_ACS_SE'] = se_prop(db1.PRENTER_ACS, db.ACS12_5yr_B25002001,\n",
    "                                db.ACS12_5yr_B25003003s, db.ACS12_5yr_B25002001s)\n",
    "db1['QNRRES_ACS_SE'] = se_prop(db1.QNRRES_ACS, db.ACS12_5yr_B01003001,db.ACS12_5yr_B09020021s, db.ACS12_5yr_B01003001s)\n",
    "db1['QFEMALE_ACS_SE'] = se_prop(db1.QFEMALE_ACS, db.ACS12_5yr_B01003001,\n",
    "                                db.ACS12_5yr_B01001026s, db.ACS12_5yr_B01003001s)\n",
    "db1['QFHH_ACS_SE'] = se_prop(db1.QFHH_ACS, db.ACS12_5yr_B11001001,db.ACS12_5yr_B11001006s, db.ACS12_5yr_B11001001s)\n",
    "db1['QUNOCCHU_ACS_SE'] = se_prop(db1.QUNOCCHU_ACS, db.ACS12_5yr_B25002001,\n",
    "                                 db.ACS12_5yr_B25002003s, db.ACS12_5yr_B25002001s)\n",
    "\n",
    "# ACS standard errors (original)\n",
    "db1['PERCAP_SE'] = se_ratio(db1.PERCAP, db.ACS12_5yr_B01003001,\n",
    "                            db.ACS12_5yr_B19025001s, db.ACS12_5yr_B01003001s)\n",
    "\n",
    "QESL_sen = se_sum(db.ACS12_5yr_B16004029s, db.ACS12_5yr_B16004030s,db.ACS12_5yr_B16004034s, db.ACS12_5yr_B16004035s, db.ACS12_5yr_B16004039s, db.ACS12_5yr_B16004040s, db.ACS12_5yr_B16004044s, db.ACS12_5yr_B16004045s, db.ACS12_5yr_B16004051s, db.ACS12_5yr_B16004052s, db.ACS12_5yr_B16004056s, db.ACS12_5yr_B16004057s, db.ACS12_5yr_B16004061s, db.ACS12_5yr_B16004062s, db.ACS12_5yr_B16004066s, db.ACS12_5yr_B16004067s)\n",
    "QESL_sed = se_sum(db.ACS12_5yr_B16004024s, db.ACS12_5yr_B16004046s,db.ACS12_5yr_B16004025s, db.ACS12_5yr_B16004047s)\n",
    "db1['QESL_SE'] = se_prop(db1.QESL, (db.ACS12_5yr_B16004024 +\n",
    "                                    db.ACS12_5yr_B16004046) -(db.ACS12_5yr_B16004025 + db.ACS12_5yr_B16004047), QESL_sen, QESL_sed)\n",
    "db1.QESL_SE = db1.QESL_SE.replace([np.inf, -np.inf], 0)\n",
    "db1.QESL_SE[db1.QESL == 0] = 0\n",
    "\n",
    "QCVLUN_sen = se_sum(db.ACS12_5yr_B23022025s, db.ACS12_5yr_B23022049s)\n",
    "db1['QCVLUN_SE'] = se_prop(db1.QCVLUN, db.ACS12_5yr_B23022001,QCVLUN_sen, db.ACS12_5yr_B23022001s)\n",
    "\n",
    "db1['QPOVTY_SE'] = se_prop(db1.QPOVTY, db.ACS12_5yr_B17021001, db.ACS12_5yr_B17021002s, db.ACS12_5yr_B17021001s)\n",
    "db1['QMOHO_SE'] = se_prop(db1.QMOHO, db.ACS12_5yr_B25024001, db.ACS12_5yr_B25024010s, db.ACS12_5yr_B25024001s)\n",
    "\n",
    "QED12LES_sen = se_sum(db.ACS12_5yr_B15002003s, db.ACS12_5yr_B15002004s, db.ACS12_5yr_B15002005s, db.ACS12_5yr_B15002006s, db.ACS12_5yr_B15002007s, db.ACS12_5yr_B15002008s, db.ACS12_5yr_B15002009s, db.ACS12_5yr_B15002010s, db.ACS12_5yr_B15002020s, db.ACS12_5yr_B15002021s, db.ACS12_5yr_B15002022s, db.ACS12_5yr_B15002023s, db.ACS12_5yr_B15002024s, db.ACS12_5yr_B15002025s, db.ACS12_5yr_B15002026s, db.ACS12_5yr_B15002027s)\n",
    "db1['QED12LES_SE'] = se_prop(db1.QED12LES, db.ACS12_5yr_B15002001,\n",
    "                             QED12LES_sen, db.ACS12_5yr_B15002001s)\n",
    "\n",
    "db1['QFEMLBR_SE'] = se_prop(db1.QFEMLBR, db.ACS12_5yr_C24010001,\n",
    "                            db.ACS12_5yr_C24010038s, db.ACS12_5yr_C24010001s)\n",
    "\n",
    "QEXTRCT_sen = se_sum(db.ACS12_5yr_C24030003s, db.ACS12_5yr_C24030030s)\n",
    "db1['QEXTRCT_SE'] = se_prop(db1.QEXTRCT, db.ACS12_5yr_C24030001,\n",
    "                            QEXTRCT_sen, db.ACS12_5yr_C24030001s)\n",
    "\n",
    "QSERV_sen = se_sum(db.ACS12_5yr_C24010019s, db.ACS12_5yr_C24010055s)\n",
    "db1['QSERV_SE'] = se_prop(db1.QSERV, db.ACS12_5yr_C24010001, QSERV_sen, db.ACS12_5yr_C24010001s)\n",
    "\n",
    "db1['QSSBEN_SE'] = se_prop(db1.QSSBEN, db.ACS12_5yr_B19055001, db.ACS12_5yr_B19055002s, db.ACS12_5yr_B19055001s)\n",
    "\n",
    "QNOAUTO_sen = se_sum(db.ACS12_5yr_B25044003s, db.ACS12_5yr_B25044010s)\n",
    "db1['QNOAUTO_SE'] = se_prop(db1.QNOAUTO, db.ACS12_5yr_B25044001, QNOAUTO_sen, db.ACS12_5yr_B25044001s)\n",
    "\n",
    "db1['QFAM_SE'] = se_prop(db1.QFAM, db.ACS12_5yr_B09002001, db.ACS12_5yr_B09002002s, db.ACS12_5yr_B09002001s)\n",
    "db1.QFAM_SE = db1.QFAM_SE.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "db1['QRICH200K_SE'] = se_prop(db1.QRICH200K, db.ACS12_5yr_B11001001, db.ACS12_5yr_B19001017s, db.ACS12_5yr_B11001001s)\n",
    "\n",
    "#############################\n",
    "\n",
    "# ACS standard errors (alternatives)\n",
    "db1['PERCAP_ALT_SE'] = se_ratio(db1.PERCAP_ALT, db.ACS12_5yr_B25008001, db.ACS12_5yr_B19025001s, db.ACS12_5yr_B25008001s)\n",
    "\n",
    "QESL_ALT_sen = se_sum(db.ACS12_5yr_B06007005s, db.ACS12_5yr_B06007008s)\n",
    "db1['QESL_ALT_SE'] = se_prop(db1.QESL_ALT, db.ACS12_5yr_B06007001, QESL_ALT_sen, db.ACS12_5yr_B06007001s)\n",
    "\n",
    "db1['QED12LES_ALT_SE'] = se_prop(db1.QED12LES_ALT, db.ACS12_5yr_B16010001, db.ACS12_5yr_B16010002s, db.ACS12_5yr_B16010001s)\n",
    "db1['QEXTRCT_ALT_SE'] = se_prop(db1.QEXTRCT_ALT, db.ACS12_5yr_C24050001, db.ACS12_5yr_C24050002s, db.ACS12_5yr_C24050001s)\n",
    "db1['QSERV_ALT_SE'] = se_prop(db1.QSERV_ALT, db.ACS12_5yr_C24050001, db.ACS12_5yr_C24050029s, db.ACS12_5yr_C24050001s)\n",
    "db1['QNOAUTO_ALT_SE'] = se_prop(db1.QNOAUTO_ALT, db.ACS12_5yr_B08201001, db.ACS12_5yr_B08201002s, db.ACS12_5yr_B08201001s)\n",
    "db1['MDGRENT_ALT_SE'] = db.ACS12_5yr_B25064001s\n",
    "db1['MHSEVAL_ALT_SE'] = db.ACS12_5yr_B25077001s\n",
    "db1.MHSEVAL_ALT_SE[np.isnan(db1.MHSEVAL_ALT)] = db1.MHSEVAL_ALT_LAG_SE[np.isnan(db1.MHSEVAL_ALT)]  # replace NA with lag\n",
    "db1.MHSEVAL_ALT_SE[np.isnan(db1.MHSEVAL_ALT_SE)] = db1.MHSEVAL_ALT_LAG_SE[np.isnan(db1.MHSEVAL_ALT_SE)]  # replace NA with lag\n",
    "db1['POPDENS_SE'] = se_ratio(db1.POPDENS, db.SE_T02A_002,\n",
    "                             db.ACS12_5yr_B01003001s,\n",
    "                             0)  # these are nearly all zero since county pops tend to have 0 MOE\n",
    "\n",
    "# Unit test for equivalency\n",
    "equal_test(db1.QUNOCCHU, db1.QUNOCCHU_ALT)\n",
    "equal_test(db1.QED12LES, db1.QED12LES_ALT)\n",
    "equal_test(db1.QEXTRCT, db1.QEXTRCT_ALT)\n",
    "equal_test(db1.QSERV, db1.QSERV_ALT)\n",
    "equal_test(db1.QNOAUTO, db1.QNOAUTO_ALT)\n",
    "\n",
    "# Add in the sample sizes\n",
    "db1['sample_person'] = db.ACS12_5yr_B00001001\n",
    "db1['sample_hu'] = db.ACS12_5yr_B00002001\n",
    "\n",
    "# Save data if main\n",
    "if __name__ == \"__main__\":\n",
    "    db1.to_csv(os.path.join(path, 'sovi_inputs.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1d1c3-1df8-48d8-a6b7-b67e5014beb1",
   "metadata": {},
   "source": [
    "It appears that ps.queen_from_shapefile is no longer available...\n",
    "Tried two newer versions... need to figure out how to get them to work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

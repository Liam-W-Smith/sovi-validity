{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe154893-1072-498a-9cf7-3366c34edf00",
   "metadata": {},
   "source": [
    "# It runs now!!\n",
    "## Fixed issues:\n",
    "- Queen \n",
    "- ix\n",
    "- file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86662a3f-25f0-4e5d-9cfc-aef2699c168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not pull supplementary ACS data - A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n",
      "  warnings.warn(dep_msg, FutureWarning)\n",
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n",
      "  warnings.warn(dep_msg, FutureWarning)\n",
      "/Users/liamsmith/opt/anaconda3/lib/python3.9/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 10 disconnected components.\n",
      " There are 7 islands with ids: 68, 546, 547, 549, 1226, 1876, 2976.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 68, ' is an island (no neighbors)')\n",
      "('WARNING: ', 546, ' is an island (no neighbors)')\n",
      "('WARNING: ', 547, ' is an island (no neighbors)')\n",
      "('WARNING: ', 549, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1226, ' is an island (no neighbors)')\n",
      "('WARNING: ', 1876, ' is an island (no neighbors)')\n",
      "('WARNING: ', 2976, ' is an island (no neighbors)')\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env \n",
    "\n",
    "# This script loads and prepares Census and ACS data.\n",
    "# Outputs a CSV file that can be used for the construction of SoVI\n",
    "# Interpolates missing values using nearby values\n",
    "# Calculates SE for compositve variables\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pysal as ps\n",
    "import numpy as np\n",
    "import libpysal as lps\n",
    "# @TODO: Finish Doc strings\n",
    "# @TODO: Cleanup file\n",
    "\n",
    "\n",
    "pd.set_option(\"chained_assignment\", None)\n",
    "\n",
    "# path = os.getcwd()\n",
    "path = os.path.dirname(os.getcwd()) # if running from the 'code' directory\n",
    "outPath=os.path.join(path,'data')\n",
    "ipath = os.path.join(path,'data','input')\n",
    "spath = os.path.join(path,'data','spatial')\n",
    "#\n",
    "# functions fot the calculation of SE\n",
    "\n",
    "\n",
    "def se_sum(*ses):\n",
    "    \"\"\"\n",
    "    compute the standard errors for a composite (sum) variable)\n",
    "\n",
    "    :param ses: an arbitrary number of standard errors for variables participating in a sum (composite variable)\n",
    "    :return: Data frame containing standard errors for the composite variable\n",
    "    \"\"\"\n",
    "\n",
    "    df_temp = pd.DataFrame(list(ses))\n",
    "    df_temp = df_temp.T\n",
    "    df_temp = np.square(df_temp)\n",
    "    df_temp = df_temp.sum(1)\n",
    "    return np.sqrt(df_temp)\n",
    "\n",
    "\n",
    "# SE of a ratio\n",
    "def se_ratio(est, estd, sen, sed):\n",
    "    \"\"\"\n",
    "\n",
    "    :param est:\n",
    "    :param estd:\n",
    "    :param sen:\n",
    "    :param sed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    sen2 = np.square(sen)\n",
    "    sed2 = np.square(sed)\n",
    "    est2 = np.square(est)\n",
    "    num = np.sqrt(sen2 + (est2 * sed2))\n",
    "    return num / estd\n",
    "\n",
    "\n",
    "# SE of a proprotion\n",
    "def se_prop(est, estd, sen, sed):\n",
    "    sen2 = np.square(sen)\n",
    "    sed2 = np.square(sed)\n",
    "    est2 = np.square(est)\n",
    "    num = sen2 - (est2 * sed2)\n",
    "    num_alt = sen2 + (est2 * sed2)\n",
    "    problems = num <= 0\n",
    "    num[problems] = num_alt[problems]\n",
    "    num = np.sqrt(num)\n",
    "    return num / estd\n",
    "\n",
    "\n",
    "# unit test for equivalency between original and constructed variables\n",
    "def equal_test(orig, alt):\n",
    "    if np.equal(orig, alt).sum() != db.shape[0]:\n",
    "        if (db.shape[0] - np.equal(orig, alt).sum()) \\\n",
    "                == np.isnan(orig).sum() == np.isnan(alt).sum():\n",
    "            pass\n",
    "        else:\n",
    "            print(\"problem in equal test\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# define data types\n",
    "make_strings = {'Geo_FIPS': object, 'Geo_STATE': object, 'Geo_COUNTY': object,\n",
    "                'Geo_TRACT': object, 'Geo_CBSA': object, 'Geo_CSA': object}\n",
    "\n",
    "# load data\n",
    "# JOE: I had to change the encoding to latin-1 to avoid hitting a UTF-8 error\n",
    "# their paper says they just use the ACS data -- but they pull in both ACS and decennial data\n",
    "acs = pd.read_csv(os.path.join(ipath, 'sovi_acs.csv'),\n",
    "                  dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "census = pd.read_csv(os.path.join(ipath, 'sovi_decennial.csv'),\n",
    "                     dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "acs_samp = pd.read_csv(os.path.join(ipath, 'sovi_acs_sampSize.csv'),\n",
    "                       dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "\n",
    "# format FIPS\n",
    "acs.index = 'g' + acs.Geo_FIPS\n",
    "census.index = 'g' + census.Geo_FIPS\n",
    "acs_samp.index = 'g' + acs_samp.Geo_FIPS\n",
    "\n",
    "# merge files\n",
    "db = census\n",
    "db = db.join(acs, rsuffix='_acs')\n",
    "db = db.join(acs_samp, rsuffix='_acsSamp')\n",
    "\n",
    "# if available add supplmentary data\n",
    "try:\n",
    "    census_sup1 = pd.read_csv(os.path.join(ipath, 'sovi_decennial_sup1.csv'),\n",
    "        dtype=make_strings,skiprows=1,encoding='latin-1')\n",
    "    census_sup1.index = 'g' + census_sup1.Geo_FIPS\n",
    "    db = db.join(census_sup1, rsuffix='_decSup1')\n",
    "except:\n",
    "    print(\"no supplementary decennial data\")\n",
    "try:\n",
    "    acs_sup1 = pd.read_csv(os.path.join(spath, 'sovi_acs_sup1.csv'),\n",
    "        dtype=make_strings,skiprows=1,encoding='latin-1')\n",
    "    acs_sup1.index = 'g' + acs_sup1.Geo_FIPS\n",
    "    db = db.join(acs_sup1, rsuffix='_acsSup1')\n",
    "except:\n",
    "    print(\"did not pull supplementary ACS data - A\")\n",
    "try:\n",
    "    acs_sup2 = pd.read_csv(os.path.join(ipath, 'sovi_acs_kids.csv'),\n",
    "                           dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "    acs_sup2.index = 'g' + acs_sup2.Geo_FIPS\n",
    "    db = db.join(acs_sup2, rsuffix='_acsSup2')\n",
    "except:\n",
    "    print(\"did not pull supplementary ACS data - B\")\n",
    "\n",
    "# drop Puerto Rico (sorry PR!)\n",
    "db = db[db.Geo_STATE != '72']\n",
    "\n",
    "# define SE columns\n",
    "se_cols = [i for i in db.columns if i[-1] == 's' and i[0] == 'A']\n",
    "db[se_cols] *= (1.65 / 1.645)\n",
    "\n",
    "# calculate weights matrix\n",
    "# w = ps.queen_from_shapefile(os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "#                             idVariable='geoFIPS')\n",
    "# queen_from_shapefile is OUTDATED. New version below?\n",
    "# w = libpysal.weights.Queen.from_dataframe(os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "                            # idVariable='geoFIPS')\n",
    "# w = ps.lib.io.weights.Queen.from_dataframe(polygons = os.path.join(spath, 'USA_Counties_500k.shp'), \n",
    "                            # ids = 'geoFIPS')\n",
    "gdf = gpd.read_file(os.path.join(spath, 'USA_Counties_500k.shp'))\n",
    "\n",
    "w = lps.weights.Queen.from_shapefile(os.path.join(spath, 'USA_Counties_500k.shp'))\n",
    "    #os.path.join(spath, 'USA_Counties_500k.shp')) \n",
    "#                            ids = 'geoFIPS')\n",
    "\n",
    "w.transform = 'R'\n",
    "\n",
    "# output dataframe\n",
    "db1 = pd.DataFrame(index=db.index)\n",
    "\n",
    "# Decennial variables (original)\n",
    "db1['MEDAGE'] = db.SF1_P0130001\n",
    "db1['BLACK'] = (db.SF1_P0030003 * 1.) / db.SF1_P0010001\n",
    "db1['QNATAM'] = (db.SF1_P0030004 * 1.) / db.SF1_P0010001\n",
    "db1['QASIAN'] = (db.SF1_P0030005 * 1.) / db.SF1_P0010001\n",
    "db1['QHISP'] = (db.SF1_P0040003 * 1.) / db.SF1_P0010001\n",
    "db1['QAGEDEP'] = ((db.SF1_P0120003 + db.SF1_P0120027 + db.SF1_P0120020 +\n",
    "                   db.SF1_P0120021 + db.SF1_P0120022 + db.SF1_P0120023 +\n",
    "                   db.SF1_P0120024 + db.SF1_P0120025 + db.SF1_P0120044 +\n",
    "                   db.SF1_P0120045 + db.SF1_P0120046 + db.SF1_P0120047 +\n",
    "                   db.SF1_P0120048 + db.SF1_P0120049) * 1.) / db.SF1_P0010001\n",
    "db1['PPUNIT'] = db.SF1_H0100001 / (db.SF1_H0030002 * 1.)\n",
    "db1['PRENTER'] = (db.SF1_H0040004 * 1.) / db.SF1_H0010001\n",
    "db1['QNRRES'] = (db.SF1_P0420005 * 1.) / db.SF1_P0010001\n",
    "db1['QFEMALE'] = (db.SF1_P0120026 * 1.) / db.SF1_P0010001\n",
    "db1['QFHH'] = (db.SF1_P0190014 * 1.) / db.SF1_P0180001\n",
    "db1['QUNOCCHU'] = ((db.SF1_H0010001 - db.SF1_H0030002) * 1.) / db.SF1_H0010001\n",
    "\n",
    "# Decennial variables (alternatives)\n",
    "db1['BLACK_ALT'] = (db.SF1_P0050004 * 1.) / db.SF1_P0010001  # exclude hispanic\n",
    "db1['QNATAM_ALT'] = (db.SF1_P0050005 * 1.) / \\\n",
    "                    db.SF1_P0010001  # exclude hispanic\n",
    "db1['QASIAN_ALT'] = (db.SF1_P0050006 * 1.) / \\\n",
    "                    db.SF1_P0010001  # exclude hispanic\n",
    "db1['QNRRES_ALT'] = (db.SF1_P0430023 + db.SF1_P0430054 * 1.) / \\\n",
    "                    db.SF1_P0010001  # 65 and over living in group quarters\n",
    "# same value, simplified computation\n",
    "db1['QUNOCCHU_ALT'] = (db.SF1_H0030003 * 1.) / db.SF1_H0030001\n",
    "\n",
    "# Decennial variables (using ACS data and alternative formulations)\n",
    "db1['MEDAGE_ACS'] = db.ACS12_5yr_B01002001\n",
    "db1['BLACK_ACS'] = db.ACS12_5yr_B03002004 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QNATAM_ACS'] = db.ACS12_5yr_B03002005 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QASIAN_ACS'] = db.ACS12_5yr_B03002006 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QHISP_ACS'] = db.ACS12_5yr_B03002012 / (db.ACS12_5yr_B03002001 * 1.)\n",
    "db1['QAGEDEP_ACS'] = (db.ACS12_5yr_B06001002 + db.ACS12_5yr_B09020001) / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QPUNIT_ACS'] = db.ACS12_5yr_B25008001 / (db.ACS12_5yr_B25002002 * 1.)\n",
    "db1['PRENTER_ACS'] = db.ACS12_5yr_B25003003 / (db.ACS12_5yr_B25002001 * 1.)\n",
    "db1['QNRRES_ACS'] = db.ACS12_5yr_B09020021 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QFEMALE_ACS'] = db.ACS12_5yr_B01001026 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QFHH_ACS'] = db.ACS12_5yr_B11001006 / (db.ACS12_5yr_B11001001 * 1.)\n",
    "db1['QUNOCCHU_ACS'] = db.ACS12_5yr_B25002003 / (db.ACS12_5yr_B25002001 * 1.)\n",
    "\n",
    "# ACS variables (original)\n",
    "db1['PERCAP'] = db.ACS12_5yr_B19025001 / (db.ACS12_5yr_B01003001 * 1.)\n",
    "db1['QESL'] = ((db.ACS12_5yr_B16004029 + db.ACS12_5yr_B16004030 +\n",
    "                db.ACS12_5yr_B16004034 + db.ACS12_5yr_B16004035 +\n",
    "                db.ACS12_5yr_B16004039 + db.ACS12_5yr_B16004040 +\n",
    "                db.ACS12_5yr_B16004044 + db.ACS12_5yr_B16004045 +\n",
    "                db.ACS12_5yr_B16004051 + db.ACS12_5yr_B16004052 +\n",
    "                db.ACS12_5yr_B16004056 + db.ACS12_5yr_B16004057 +\n",
    "                db.ACS12_5yr_B16004061 + db.ACS12_5yr_B16004062 +\n",
    "                db.ACS12_5yr_B16004066 + db.ACS12_5yr_B16004067) * 1.) / \\\n",
    "              ((db.ACS12_5yr_B16004024 + db.ACS12_5yr_B16004046) - (db.ACS12_5yr_B16004025 + db.ACS12_5yr_B16004047))\n",
    "db1.QESL = db1.QESL.replace([np.inf, -np.inf, np.nan], 0)\n",
    "db1.QESL = db1.QESL.replace([np.inf, -np.inf], 0)\n",
    "db1['QCVLUN'] = ((db.ACS12_5yr_B23022025 + db.ACS12_5yr_B23022049) * 1.) / \\\n",
    "                db.ACS12_5yr_B23022001\n",
    "db1['QPOVTY'] = (db.ACS12_5yr_B17021002 * 1.) / db.ACS12_5yr_B17021001\n",
    "db1['QMOHO'] = (db.ACS12_5yr_B25024010 * 1.) / db.ACS12_5yr_B25024001\n",
    "db1['QED12LES'] = ((db.ACS12_5yr_B15002003 + db.ACS12_5yr_B15002004 +\n",
    "                    db.ACS12_5yr_B15002005 + db.ACS12_5yr_B15002006 +\n",
    "                    db.ACS12_5yr_B15002007 + db.ACS12_5yr_B15002008 +\n",
    "                    db.ACS12_5yr_B15002009 + db.ACS12_5yr_B15002010 +\n",
    "                    db.ACS12_5yr_B15002020 + db.ACS12_5yr_B15002021 +\n",
    "                    db.ACS12_5yr_B15002022 + db.ACS12_5yr_B15002023 +\n",
    "                    db.ACS12_5yr_B15002024 + db.ACS12_5yr_B15002025 +\n",
    "                    db.ACS12_5yr_B15002026 + db.ACS12_5yr_B15002027) * 1.) / \\\n",
    "                  db.ACS12_5yr_B15002001\n",
    "db1['QFEMLBR'] = (db.ACS12_5yr_C24010038 * 1.) / db.ACS12_5yr_C24010001\n",
    "db1['QEXTRCT'] = ((db.ACS12_5yr_C24030003 + db.ACS12_5yr_C24030030) * 1.) / \\\n",
    "                 db.ACS12_5yr_C24030001\n",
    "db1['QSERV'] = ((db.ACS12_5yr_C24010019 + db.ACS12_5yr_C24010055) * 1.) / \\\n",
    "               db.ACS12_5yr_C24010001\n",
    "db1['QSSBEN'] = (db.ACS12_5yr_B19055002 * 1.) / db.ACS12_5yr_B19055001\n",
    "db1['QNOAUTO'] = ((db.ACS12_5yr_B25044003 + db.ACS12_5yr_B25044010) * 1.) / \\\n",
    "                 db.ACS12_5yr_B25044001\n",
    "db1['QFAM'] = (db.ACS12_5yr_B09002002 * 1.) / db.ACS12_5yr_B09002001\n",
    "db1.QFAM = db1.QFAM.replace([np.inf, -np.inf, np.nan], 0)\n",
    "db1['QRICH200K'] = (db.ACS12_5yr_B19001017 * 1.) / db.ACS12_5yr_B11001001\n",
    "\n",
    "# ACS variables (alternatives)\n",
    "# HH income divided by persons in HHs\n",
    "db1['PERCAP_ALT'] = db.ACS12_5yr_B19025001 / (db.ACS12_5yr_B25008001 * 1.)\n",
    "\n",
    "# 5 and older who don't speak English very well\n",
    "db1['QESL_ALT'] = ((db.ACS12_5yr_B06007005 + db.ACS12_5yr_B06007008) * 1.) / \\\n",
    "                  db.ACS12_5yr_B06007001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QED12LES_ALT'] = (db.ACS12_5yr_B16010002 * 1.) / db.ACS12_5yr_B16010001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QEXTRCT_ALT'] = (db.ACS12_5yr_C24050002 * 1.) / db.ACS12_5yr_C24050001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QSERV_ALT'] = (db.ACS12_5yr_C24050029 * 1.) / db.ACS12_5yr_C24050001\n",
    "\n",
    "# same value, simplified computation\n",
    "db1['QNOAUTO_ALT'] = (db.ACS12_5yr_B08201002 * 1.) / db.ACS12_5yr_B08201001\n",
    "\n",
    "# the original computed the median by hand so is not included\n",
    "db1['MDGRENT_ALT'] = db.ACS12_5yr_B25064001\n",
    "\n",
    "# the original computed the median by hand so is not included\n",
    "db1['MHSEVAL_ALT'] = db.ACS12_5yr_B25077001\n",
    "\n",
    "# I didn't understand QURBRURX\n",
    "db1['POPDENS'] = db.ACS12_5yr_B01003001 / (db.SE_T02A_002 * 1.)\n",
    "\n",
    "# if no home value, assign the spatial lag of the estimate and SE\n",
    "# NOTE: when they do this, they appear to be doing some extra work... the goal is to replace missing home values with\n",
    "# their spatial lag. But after calculating spatial lag, they replace missing spatial lags with the home value in that county,\n",
    "# which is circular. Also we probably don't need to calculate spatial lag on the whole dataset -- why not do it for just the \n",
    "# observations that we are missing data for?\n",
    "homeval = db1['MHSEVAL_ALT'].copy()\n",
    "homeval_se = db.ACS12_5yr_B25077001s.copy()\n",
    "dbf = lps.io.open(os.path.join(spath, 'USA_Counties_500k.dbf'))\n",
    "\n",
    "# Rename dbf GEOIDs to match homeval\n",
    "geoid = dbf.by_col('geoFIPS')\n",
    "\n",
    "shp_fips = pd.DataFrame(dbf.by_col('geoFIPS'), index=geoid)\n",
    "shp_fips = shp_fips.join(homeval)\n",
    "shp_fips = shp_fips.join(homeval_se)\n",
    "shp_fips['MHSEVAL_ALT_LAG'] = lps.weights.lag_spatial(w, shp_fips.MHSEVAL_ALT)\n",
    "shp_fips['MHSEVAL_ALT_LAG_SE'] = lps.weights.lag_spatial(w, shp_fips.ACS12_5yr_B25077001s)\n",
    "\n",
    "mh = shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG == 0].MHSEVAL_ALT.tolist()\n",
    "\n",
    "# Reassign values to MHSEVAL_ALT_LAG\n",
    "shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG == 0, 'MHSEVAL_ALT_LAG'] = mh\n",
    "\n",
    "# Reassign missing standard error values\n",
    "mhs = shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG_SE == 0].ACS12_5yr_B25077001s.tolist()\n",
    "shp_fips.loc[shp_fips.MHSEVAL_ALT_LAG_SE == 0, 'MHSEVAL_ALT_LAG_SE'] = mhs\n",
    "\n",
    "# Get rid of nan values - reassign MHSEVAL_ALT(_SE)\n",
    "shp_fips.MHSEVAL_ALT_LAG[np.isnan(shp_fips.MHSEVAL_ALT_LAG)] = \\\n",
    "    shp_fips.MHSEVAL_ALT[np.isnan(shp_fips.MHSEVAL_ALT_LAG)]  # replace NA with lag\n",
    "shp_fips.MHSEVAL_ALT_LAG_SE[np.isnan(shp_fips.MHSEVAL_ALT_LAG_SE)] = \\\n",
    "    shp_fips.ACS12_5yr_B25077001s[np.isnan(shp_fips.MHSEVAL_ALT_LAG_SE)]  # replace NA with lag\n",
    "\n",
    "db1['MHSEVAL_ALT_LAG'] = shp_fips['MHSEVAL_ALT_LAG']\n",
    "db1['MHSEVAL_ALT_LAG_SE'] = shp_fips['MHSEVAL_ALT_LAG_SE']\n",
    "db1.MHSEVAL_ALT[np.isnan(db1.MHSEVAL_ALT)] = db1.MHSEVAL_ALT_LAG[np.isnan(db1.MHSEVAL_ALT)]\n",
    "# note: the lagged SE is pushed to the final column in the SE section below\n",
    "\n",
    "#############################\n",
    "\n",
    "# Decennial standard errors (using ACS data and alternative formulations)\n",
    "db1['MEDAGE_ACS_SE'] = db.ACS12_5yr_B01002001s\n",
    "\n",
    "db1['BLACK_ACS_SE'] = se_prop(db1.BLACK_ACS, db.ACS12_5yr_B03002001,\n",
    "                              db.ACS12_5yr_B03002004s, db.ACS12_5yr_B03002001s)\n",
    "db1['QNATAM_ACS_SE'] = se_prop(db1.QNATAM_ACS, db.ACS12_5yr_B03002001,\n",
    "                               db.ACS12_5yr_B03002005s, db.ACS12_5yr_B03002001s)\n",
    "db1['QASIAN_ACS_SE'] = se_prop(db1.QASIAN_ACS, db.ACS12_5yr_B03002001,\n",
    "                               db.ACS12_5yr_B03002006s, db.ACS12_5yr_B03002001s)\n",
    "db1['QHISP_ACS_SE'] = se_prop(db1.QHISP_ACS, db.ACS12_5yr_B03002001,\n",
    "                              db.ACS12_5yr_B03002012s, db.ACS12_5yr_B03002001s)\n",
    "\n",
    "QAGEDEP_ACS_sen = se_sum(db.ACS12_5yr_B06001002s, db.ACS12_5yr_B09020001s)\n",
    "db1['QAGEDEP_ACS_SE'] = se_prop(db1.QAGEDEP_ACS, db.ACS12_5yr_B01003001,\n",
    "                                QAGEDEP_ACS_sen, db.ACS12_5yr_B01003001s)\n",
    "\n",
    "db1['QPUNIT_ACS_SE'] = se_ratio(db1.QPUNIT_ACS, db.ACS12_5yr_B25002002,\n",
    "                                db.ACS12_5yr_B25008001s, db.ACS12_5yr_B25002002s)\n",
    "db1['PRENTER_ACS_SE'] = se_prop(db1.PRENTER_ACS, db.ACS12_5yr_B25002001,\n",
    "                                db.ACS12_5yr_B25003003s, db.ACS12_5yr_B25002001s)\n",
    "db1['QNRRES_ACS_SE'] = se_prop(db1.QNRRES_ACS, db.ACS12_5yr_B01003001,db.ACS12_5yr_B09020021s, db.ACS12_5yr_B01003001s)\n",
    "db1['QFEMALE_ACS_SE'] = se_prop(db1.QFEMALE_ACS, db.ACS12_5yr_B01003001,\n",
    "                                db.ACS12_5yr_B01001026s, db.ACS12_5yr_B01003001s)\n",
    "db1['QFHH_ACS_SE'] = se_prop(db1.QFHH_ACS, db.ACS12_5yr_B11001001,db.ACS12_5yr_B11001006s, db.ACS12_5yr_B11001001s)\n",
    "db1['QUNOCCHU_ACS_SE'] = se_prop(db1.QUNOCCHU_ACS, db.ACS12_5yr_B25002001,\n",
    "                                 db.ACS12_5yr_B25002003s, db.ACS12_5yr_B25002001s)\n",
    "\n",
    "# ACS standard errors (original)\n",
    "db1['PERCAP_SE'] = se_ratio(db1.PERCAP, db.ACS12_5yr_B01003001,\n",
    "                            db.ACS12_5yr_B19025001s, db.ACS12_5yr_B01003001s)\n",
    "\n",
    "QESL_sen = se_sum(db.ACS12_5yr_B16004029s, db.ACS12_5yr_B16004030s,db.ACS12_5yr_B16004034s, db.ACS12_5yr_B16004035s, db.ACS12_5yr_B16004039s, db.ACS12_5yr_B16004040s, db.ACS12_5yr_B16004044s, db.ACS12_5yr_B16004045s, db.ACS12_5yr_B16004051s, db.ACS12_5yr_B16004052s, db.ACS12_5yr_B16004056s, db.ACS12_5yr_B16004057s, db.ACS12_5yr_B16004061s, db.ACS12_5yr_B16004062s, db.ACS12_5yr_B16004066s, db.ACS12_5yr_B16004067s)\n",
    "QESL_sed = se_sum(db.ACS12_5yr_B16004024s, db.ACS12_5yr_B16004046s,db.ACS12_5yr_B16004025s, db.ACS12_5yr_B16004047s)\n",
    "db1['QESL_SE'] = se_prop(db1.QESL, (db.ACS12_5yr_B16004024 +\n",
    "                                    db.ACS12_5yr_B16004046) -(db.ACS12_5yr_B16004025 + db.ACS12_5yr_B16004047), QESL_sen, QESL_sed)\n",
    "db1.QESL_SE = db1.QESL_SE.replace([np.inf, -np.inf], 0)\n",
    "db1.QESL_SE[db1.QESL == 0] = 0\n",
    "\n",
    "QCVLUN_sen = se_sum(db.ACS12_5yr_B23022025s, db.ACS12_5yr_B23022049s)\n",
    "db1['QCVLUN_SE'] = se_prop(db1.QCVLUN, db.ACS12_5yr_B23022001,QCVLUN_sen, db.ACS12_5yr_B23022001s)\n",
    "\n",
    "db1['QPOVTY_SE'] = se_prop(db1.QPOVTY, db.ACS12_5yr_B17021001, db.ACS12_5yr_B17021002s, db.ACS12_5yr_B17021001s)\n",
    "db1['QMOHO_SE'] = se_prop(db1.QMOHO, db.ACS12_5yr_B25024001, db.ACS12_5yr_B25024010s, db.ACS12_5yr_B25024001s)\n",
    "\n",
    "QED12LES_sen = se_sum(db.ACS12_5yr_B15002003s, db.ACS12_5yr_B15002004s, db.ACS12_5yr_B15002005s, db.ACS12_5yr_B15002006s, db.ACS12_5yr_B15002007s, db.ACS12_5yr_B15002008s, db.ACS12_5yr_B15002009s, db.ACS12_5yr_B15002010s, db.ACS12_5yr_B15002020s, db.ACS12_5yr_B15002021s, db.ACS12_5yr_B15002022s, db.ACS12_5yr_B15002023s, db.ACS12_5yr_B15002024s, db.ACS12_5yr_B15002025s, db.ACS12_5yr_B15002026s, db.ACS12_5yr_B15002027s)\n",
    "db1['QED12LES_SE'] = se_prop(db1.QED12LES, db.ACS12_5yr_B15002001,\n",
    "                             QED12LES_sen, db.ACS12_5yr_B15002001s)\n",
    "\n",
    "db1['QFEMLBR_SE'] = se_prop(db1.QFEMLBR, db.ACS12_5yr_C24010001,\n",
    "                            db.ACS12_5yr_C24010038s, db.ACS12_5yr_C24010001s)\n",
    "\n",
    "QEXTRCT_sen = se_sum(db.ACS12_5yr_C24030003s, db.ACS12_5yr_C24030030s)\n",
    "db1['QEXTRCT_SE'] = se_prop(db1.QEXTRCT, db.ACS12_5yr_C24030001,\n",
    "                            QEXTRCT_sen, db.ACS12_5yr_C24030001s)\n",
    "\n",
    "QSERV_sen = se_sum(db.ACS12_5yr_C24010019s, db.ACS12_5yr_C24010055s)\n",
    "db1['QSERV_SE'] = se_prop(db1.QSERV, db.ACS12_5yr_C24010001, QSERV_sen, db.ACS12_5yr_C24010001s)\n",
    "\n",
    "db1['QSSBEN_SE'] = se_prop(db1.QSSBEN, db.ACS12_5yr_B19055001, db.ACS12_5yr_B19055002s, db.ACS12_5yr_B19055001s)\n",
    "\n",
    "QNOAUTO_sen = se_sum(db.ACS12_5yr_B25044003s, db.ACS12_5yr_B25044010s)\n",
    "db1['QNOAUTO_SE'] = se_prop(db1.QNOAUTO, db.ACS12_5yr_B25044001, QNOAUTO_sen, db.ACS12_5yr_B25044001s)\n",
    "\n",
    "db1['QFAM_SE'] = se_prop(db1.QFAM, db.ACS12_5yr_B09002001, db.ACS12_5yr_B09002002s, db.ACS12_5yr_B09002001s)\n",
    "db1.QFAM_SE = db1.QFAM_SE.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "db1['QRICH200K_SE'] = se_prop(db1.QRICH200K, db.ACS12_5yr_B11001001, db.ACS12_5yr_B19001017s, db.ACS12_5yr_B11001001s)\n",
    "\n",
    "#############################\n",
    "\n",
    "# ACS standard errors (alternatives)\n",
    "db1['PERCAP_ALT_SE'] = se_ratio(db1.PERCAP_ALT, db.ACS12_5yr_B25008001, db.ACS12_5yr_B19025001s, db.ACS12_5yr_B25008001s)\n",
    "\n",
    "QESL_ALT_sen = se_sum(db.ACS12_5yr_B06007005s, db.ACS12_5yr_B06007008s)\n",
    "db1['QESL_ALT_SE'] = se_prop(db1.QESL_ALT, db.ACS12_5yr_B06007001, QESL_ALT_sen, db.ACS12_5yr_B06007001s)\n",
    "\n",
    "db1['QED12LES_ALT_SE'] = se_prop(db1.QED12LES_ALT, db.ACS12_5yr_B16010001, db.ACS12_5yr_B16010002s, db.ACS12_5yr_B16010001s)\n",
    "db1['QEXTRCT_ALT_SE'] = se_prop(db1.QEXTRCT_ALT, db.ACS12_5yr_C24050001, db.ACS12_5yr_C24050002s, db.ACS12_5yr_C24050001s)\n",
    "db1['QSERV_ALT_SE'] = se_prop(db1.QSERV_ALT, db.ACS12_5yr_C24050001, db.ACS12_5yr_C24050029s, db.ACS12_5yr_C24050001s)\n",
    "db1['QNOAUTO_ALT_SE'] = se_prop(db1.QNOAUTO_ALT, db.ACS12_5yr_B08201001, db.ACS12_5yr_B08201002s, db.ACS12_5yr_B08201001s)\n",
    "db1['MDGRENT_ALT_SE'] = db.ACS12_5yr_B25064001s\n",
    "db1['MHSEVAL_ALT_SE'] = db.ACS12_5yr_B25077001s\n",
    "db1.MHSEVAL_ALT_SE[np.isnan(db1.MHSEVAL_ALT)] = db1.MHSEVAL_ALT_LAG_SE[np.isnan(db1.MHSEVAL_ALT)]  # replace NA with lag\n",
    "db1.MHSEVAL_ALT_SE[np.isnan(db1.MHSEVAL_ALT_SE)] = db1.MHSEVAL_ALT_LAG_SE[np.isnan(db1.MHSEVAL_ALT_SE)]  # replace NA with lag\n",
    "db1['POPDENS_SE'] = se_ratio(db1.POPDENS, db.SE_T02A_002,\n",
    "                             db.ACS12_5yr_B01003001s,\n",
    "                             0)  # these are nearly all zero since county pops tend to have 0 MOE\n",
    "\n",
    "# Unit test for equivalency\n",
    "equal_test(db1.QUNOCCHU, db1.QUNOCCHU_ALT)\n",
    "equal_test(db1.QED12LES, db1.QED12LES_ALT)\n",
    "equal_test(db1.QEXTRCT, db1.QEXTRCT_ALT)\n",
    "equal_test(db1.QSERV, db1.QSERV_ALT)\n",
    "equal_test(db1.QNOAUTO, db1.QNOAUTO_ALT)\n",
    "\n",
    "# Add in the sample sizes\n",
    "db1['sample_person'] = db.ACS12_5yr_B00001001\n",
    "db1['sample_hu'] = db.ACS12_5yr_B00002001\n",
    "\n",
    "# Save data if main\n",
    "if __name__ == \"__main__\":\n",
    "    db1.to_csv(os.path.join(path, 'sovi_inputs.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b0e7d-9e50-4298-8834-5a8f378b877f",
   "metadata": {},
   "source": [
    "# Checking my numbers match those in the paper\n",
    "\n",
    "### Total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7140acf4-124a-4256-bd5e-5a9bbd4bad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACS12_5yr_B03002001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_FIPS</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g01001</th>\n",
       "      <td>54590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01003</th>\n",
       "      <td>183226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01005</th>\n",
       "      <td>27469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01007</th>\n",
       "      <td>22769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01009</th>\n",
       "      <td>57466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01011</th>\n",
       "      <td>10779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01013</th>\n",
       "      <td>20730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01015</th>\n",
       "      <td>117834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01017</th>\n",
       "      <td>34228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01019</th>\n",
       "      <td>25917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACS12_5yr_B03002001\n",
       "Geo_FIPS                     \n",
       "g01001                  54590\n",
       "g01003                 183226\n",
       "g01005                  27469\n",
       "g01007                  22769\n",
       "g01009                  57466\n",
       "g01011                  10779\n",
       "g01013                  20730\n",
       "g01015                 117834\n",
       "g01017                  34228\n",
       "g01019                  25917"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[['ACS12_5yr_B03002001']].sort_values(by = \"Geo_FIPS\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ad41c-d572-4108-8aed-c0cd262ecda3",
   "metadata": {},
   "source": [
    "## Percent Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e266ef0c-9732-4e8c-9721-0a9503f93c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLACK_ACS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_FIPS</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g01001</th>\n",
       "      <td>0.179447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01003</th>\n",
       "      <td>0.092356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01005</th>\n",
       "      <td>0.459063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01007</th>\n",
       "      <td>0.217137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01009</th>\n",
       "      <td>0.012355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01011</th>\n",
       "      <td>0.705910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01013</th>\n",
       "      <td>0.432272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01015</th>\n",
       "      <td>0.205068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01017</th>\n",
       "      <td>0.390996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01019</th>\n",
       "      <td>0.047614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BLACK_ACS\n",
       "Geo_FIPS           \n",
       "g01001     0.179447\n",
       "g01003     0.092356\n",
       "g01005     0.459063\n",
       "g01007     0.217137\n",
       "g01009     0.012355\n",
       "g01011     0.705910\n",
       "g01013     0.432272\n",
       "g01015     0.205068\n",
       "g01017     0.390996\n",
       "g01019     0.047614"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1[['BLACK_ACS']].sort_values(by = \"Geo_FIPS\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643bcb4-42eb-4767-ba28-9690051d7597",
   "metadata": {},
   "source": [
    "## Percent Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9672fe5e-e193-4958-a910-b937eda7f38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QASIAN_ACS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo_FIPS</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g01001</th>\n",
       "      <td>0.008042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01003</th>\n",
       "      <td>0.007352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01005</th>\n",
       "      <td>0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01007</th>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01009</th>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01011</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01013</th>\n",
       "      <td>0.008828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01015</th>\n",
       "      <td>0.006679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01017</th>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g01019</th>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          QASIAN_ACS\n",
       "Geo_FIPS            \n",
       "g01001      0.008042\n",
       "g01003      0.007352\n",
       "g01005      0.002039\n",
       "g01007      0.001098\n",
       "g01009      0.001688\n",
       "g01011      0.000000\n",
       "g01013      0.008828\n",
       "g01015      0.006679\n",
       "g01017      0.005200\n",
       "g01019      0.003010"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1[['QASIAN_ACS']].sort_values(by = \"Geo_FIPS\").head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
